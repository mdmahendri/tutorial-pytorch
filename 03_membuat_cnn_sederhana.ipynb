{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model CNN Sesuai LeNet-5\n",
    "Proses pembuatan model CNN akan memanfaatkan subclass dari `nn.Module`. Fungsi dari `Module` ini adalah sebagai wadah berbagai parameter yang akan dilatih. Parameter pada model dapat diakses lewat method `.parameters()`. Selain itu kita hanya perlu implementasi method `forward` dari subclass yang dibuat dan perhitungan gradien `autograd` dapat berjalan secara otomatis seperti pada contoh notebook sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/03cnn.png)\n",
    "Langkah-langkah pembuatan CNN  \n",
    "1. Definisi model beserta parameter sesuai gambar di atas\n",
    "2. Hitung loss/cost nya dan lakukan backpropagation\n",
    "4. Update parameter\n",
    "\n",
    "Untuk menghitung ukuran kernel/filter memakai formula: $n_{in} - [stride * (n_{out} - 1) - (2 * padding)]$ Default pada PyTorch memakai stride 1 dan padding 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definisi Model dan Parameter\n",
    "LeNet yang dibuat kali ini tidak memakai softmax seperti yang seharusnya. Definisikan layer-layer apa saja yang digunakan pada `__init()__` sehingga pada method `.forward()` hanya perlu menuliskan `Function` apa yang digunakan. Perlu diperhatikan untuk mendefinisikan layer selalu gunakan `torch.nn`. Sedangkan `torch.nn.functional` hanya digunakan ketika membuat layer custom atau fungsi tanpa parameter. Detail contohnya bisa dilihat pada [post forum PyTorch ini](https://discuss.pytorch.org/t/how-to-choose-between-torch-nn-functional-and-torch-nn-module/2800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() #hanya berfungsi pada python3\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5)\n",
    "        self.fc1 = nn.Linear(in_features = 16 * 5 * 5, out_features = 120) #dengan bias, karena defaultnya True\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(input = x, kernel_size = (2, 2)) #size dapat memakai rumus di atas dengan memisalkan stride 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2) #jika persegi tidak wajib memakai tuple\n",
    "        x = x.view(x.size(0), -1) #cara ini agak berbeda dengan dokumentasi PyTorch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arsitektur CNN dapat diketahui dengan menginisiasi kelas dan `print` instance tersebut. Seperti disebutkan di atas, parameter bisa diakses melalui method `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Daftar parameter yang ada pada model: \n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([6, 1, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 6, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([120, 400])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([120])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([84, 120])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([84])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 84])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "cnn = LeNet()\n",
    "print(cnn)\n",
    "\n",
    "print('\\nDaftar parameter yang ada pada model: ')\n",
    "for param in cnn.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti terlihat pada hasil di atas, setiap parameter adalah instance dari kelas `Parameter`, sejenis `Tensor` yang otomatis menjadi atribut pada saat mendefinisikan suatu layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hitung Cost dan Melakukan Backpropagation\n",
    "Dimulai dengan memproses input tanpa memakai cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0148, -0.0450, -0.0557, -0.1197,  0.0675,  0.0357,  0.0961, -0.0396,\n",
      "         -0.0412, -0.0434]], grad_fn=<ThAddmmBackward>)\n",
      "\n",
      "Sebelum dilakukan operasi propagation\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Setelah dilakukan operasi propagation\n",
      " tensor([-1.2412, -1.8414, -0.9265,  0.0479, -1.0891, -0.5778, -0.4866, -0.3193,\n",
      "        -0.1597, -0.9485])\n"
     ]
    }
   ],
   "source": [
    "input_img = torch.randn(1, 1, 32, 32)\n",
    "output = cnn(input_img)\n",
    "print(output)\n",
    "\n",
    "cnn.zero_grad() #menghilangkan gradien yang masih tersimpan seperti yang dijelaskan pada notebook sebelumnya\n",
    "print('\\nSebelum dilakukan operasi propagation\\n', cnn.fc3.bias.grad)\n",
    "\n",
    "output.backward(torch.randn(1, 10)) \n",
    "print('\\nSetelah dilakukan operasi propagation\\n', cnn.fc3.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perlu diperhatikan bahwa PyTorch hanya mendukung proses secara mini-batch sehingga fungsi dari dimensi yang pertama adalah menyatakan mini-batch 1. Selanjutnya dilakukan backpropagation memakai cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0095, grad_fn=<MseLossBackward>)\n",
      "\n",
      "Sebelum dilakukan operasi propagation\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Setelah dilakukan operasi propagation\n",
      " tensor([-0.2953, -0.0516,  0.0052, -0.2398, -0.0845, -0.2311, -0.0491, -0.3279,\n",
      "        -0.2578, -0.1393])\n"
     ]
    }
   ],
   "source": [
    "output = cnn(input_img)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1) #ingat, mini-batch\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "cost = criterion(output, target)\n",
    "print(cost)\n",
    "\n",
    "cnn.zero_grad() #menghilangkan gradien yang masih tersimpan seperti yang dijelaskan pada notebook sebelumnya\n",
    "print('\\nSebelum dilakukan operasi propagation\\n', cnn.fc3.bias.grad)\n",
    "\n",
    "cost.backward()\n",
    "print('\\nSetelah dilakukan operasi propagation\\n', cnn.fc3.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Parameter\n",
    "Setelah gradien tersimpan pada `.grad` maka selanjutnya adalah melakukan update semua parameter memakai nilai gradien tersebut. Berikut cara melakukan optimisasi memakai SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for param in cnn.parameters():\n",
    "    param.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selain bisa dilakukan secara manual seperti di atas, PyTorch juga menyediakan package optimisasi pada `torch.optim`. Contoh pemakaiannya ada di bawah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sebelum dilakukan update\n",
      " tensor([-0.0245, -0.0543, -0.0661, -0.0850,  0.0445,  0.0335,  0.0721, -0.0089,\n",
      "        -0.0781, -0.0942])\n",
      "\n",
      "Setelah dilakukan update\n",
      " tensor([-0.0242, -0.0543, -0.0661, -0.0848,  0.0445,  0.0338,  0.0722, -0.0086,\n",
      "        -0.0779, -0.0940])\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(cnn.parameters(), lr = 1e-3) #membuat optimizer\n",
    "\n",
    "print('\\nSebelum dilakukan update\\n', cnn.fc3.bias.data)\n",
    "\n",
    "#gunakan saat iterasi training\n",
    "optimizer.zero_grad() #jangan lupa\n",
    "output = cnn(input_img)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() #update parameter\n",
    "\n",
    "print('\\nSetelah dilakukan update\\n', cnn.fc3.bias.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
